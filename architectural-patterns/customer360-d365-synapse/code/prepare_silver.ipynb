{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Prepare SILVER\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {},
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Spark Config\n",
        "\n",
        "spark.conf.set(\"fs.azure.account.auth.type\", \"SAS\")\n",
        "spark.conf.set(\"fs.azure.sas.token.provider.type\", \"com.microsoft.azure.synapse.tokenlibrary.ConfBasedSASProvider\")\n",
        "spark.conf.set(\"spark.storage.synapse.sas\", \"\")\n",
        "\n",
        "storage_account_name = \"stgd365analytics\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "from datetime import datetime\n",
        "\n",
        "dataverse_customer_table_name = 'crc33_customer'\n",
        "bronze_container_name = 'bronze'\n",
        "silver_container_name = 'silver'\n",
        "partition_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "raw_table_df = spark.read.option(\"header\", \"true\").option(\"multiLine\", \"true\").csv(f\"abfss://{bronze_container_name}@{storage_account_name}.dfs.core.windows.net/{dataverse_customer_table_name}/{partition_date}\")\n",
        "\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_postcode\", \"PostCode\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_state\", \"State\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_lastname\", \"LastName\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_country\", \"Country\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_gender\", \"Gender\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_streetaddress\", \"StreetAddress\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_name\", \"Name\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_telephone\", \"Telephone\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_dateofbirth\", \"DateOfBirth\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_city\", \"City\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_firstname\", \"FirstName\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_email\", \"Email\")\n",
        "raw_table_df = raw_table_df.withColumnRenamed(\"crc33_cid\", \"cid\")\n",
        "\n",
        "silver_table_df = raw_table_df.select(col(\"cid\"),col(\"postcode\"), col(\"state\"),col(\"lastname\"),col(\"country\"),col(\"gender\"),col(\"streetaddress\"),col(\"name\"),col(\"telephone\"),col(\"dateofbirth\"),col(\"city\"),col(\"firstname\"),col(\"email\"))\n",
        "\n",
        "silver_table_df.write.mode('append').parquet(f\"abfss://{silver_container_name}@{storage_account_name}.dfs.core.windows.net/{dataverse_customer_table_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "customer_spend_table_name = 'customer_spend'\n",
        "\n",
        "customer_spend_df = spark.read.option(\"header\", \"true\").csv(f\"abfss://{bronze_container_name}@{storage_account_name}.dfs.core.windows.net/{customer_spend_table_name}\")\n",
        "customer_spend_df.write.mode('append').parquet(f\"abfss://{silver_container_name}@{storage_account_name}.dfs.core.windows.net/{customer_spend_table_name}\")"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
