{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Prepare BRONZE\r\n",
        "\r\n",
        "The export done by the *Synaps Link for Dataverse* is stored in the *dataverse-ENVIRONMENT-GUID* container. This notebook copies this CSV export to the **BRONZE** layer container.\r\n",
        "\r\n",
        "1. Read the model json file from the *dataverse-ENVIRONMENT-GUID* => *Microsoft.Athena.TrickleFeedService* directory and extract the column names. \r\n",
        "2. Read the csv export data under the table name directory, add the column names to the dataframe.\r\n",
        "3. Save the dataframe to the Bronze layer. Use date as partition folder name.\r\n",
        "2. Manually upload the external resident data to the residents_external directiry in the raw container."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkbasic",
              "session_id": "0",
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-03-23T12:36:42.005792Z",
              "session_start_time": null,
              "execution_start_time": "2023-03-23T12:36:42.1524472Z",
              "execution_finish_time": "2023-03-23T12:36:42.315092Z",
              "spark_jobs": null,
              "parent_msg_id": "b7ef8254-1c16-4582-976d-42d86b4293bf"
            },
            "text/plain": "StatementMeta(sparkbasic, 0, 6, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {}
      },
      "source": [
        "# Spark Config\r\n",
        "\r\n",
        "spark.conf.set(\"fs.azure.account.auth.type\", \"SAS\")\r\n",
        "spark.conf.set(\"fs.azure.sas.token.provider.type\", \"com.microsoft.azure.synapse.tokenlibrary.ConfBasedSASProvider\")\r\n",
        "spark.conf.set(\"spark.storage.synapse.sas\", \"?sv=2021-12-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2023-08-29T21:29:15Z&st=2023-03-23T12:29:15Z&spr=https&sig=ghlTFjtWaYvdXVmKQJj8uM5gt4C5P9bhuuRsoo7Y4sk%3D\")\r\n",
        "\r\n",
        "storage_account_name = \"stgd365analytics\"\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkbasic",
              "session_id": "0",
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-03-23T12:38:52.560479Z",
              "session_start_time": null,
              "execution_start_time": "2023-03-23T12:38:52.7228247Z",
              "execution_finish_time": "2023-03-23T12:38:54.6151983Z",
              "spark_jobs": null,
              "parent_msg_id": "2cf197d4-a817-42b1-9ac9-f8253fd8c11c"
            },
            "text/plain": "StatementMeta(sparkbasic, 0, 10, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Dataframe from dataverse table with header\r\n",
        "\r\n",
        "import json\r\n",
        "from pyspark.sql.types import *\r\n",
        "\r\n",
        "dataverse_link_container_name = \"dataverse-salestrial-unq48221acf3fc4ed11a10b6045bd016\"\r\n",
        "dataverse_customer_table_name = 'crc33_customer'\r\n",
        "\r\n",
        "dataverse_customer_model_df = spark.read.text(f\"abfss://{dataverse_link_container_name}@{storage_account_name}.dfs.core.windows.net/Microsoft.Athena.TrickleFeedService/{dataverse_customer_table_name}-model.json\")\r\n",
        "dataverse_customer_model_json = dataverse_customer_model_df.first()[0]\r\n",
        "dataverse_customer_model = json.loads(dataverse_customer_model_json)\r\n",
        "\r\n",
        "attributes = dataverse_customer_model['entities'][0]['attributes']\r\n",
        "dataverse_customer_table_header = [attribute['name'] for attribute in attributes]\r\n",
        "\r\n",
        "# print(dataverse_customer_table_header)\r\n",
        "\r\n",
        "schema = StructType(\r\n",
        "    [StructField(f, StringType(), True) for f in dataverse_customer_table_header]\r\n",
        ")\r\n",
        "\r\n",
        "dataverse_customer_table_df = spark.read.option(\"header\", \"false\").schema(schema).option(\"multiLine\", \"true\").csv(f\"abfss://{dataverse_link_container_name}@{storage_account_name}.dfs.core.windows.net/{dataverse_customer_table_name}/\")\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkbasic",
              "session_id": "0",
              "statement_id": 12,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-03-23T12:39:15.1286203Z",
              "session_start_time": null,
              "execution_start_time": "2023-03-23T12:39:15.2692151Z",
              "execution_finish_time": "2023-03-23T12:39:20.6549605Z",
              "spark_jobs": null,
              "parent_msg_id": "81364b04-8152-418b-993a-c717d2ca29ca"
            },
            "text/plain": "StatementMeta(sparkbasic, 0, 12, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Save to bronze layer with partition\r\n",
        "\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "bronze_container_name = 'bronze'\r\n",
        "\r\n",
        "partition_date = datetime.now().strftime(\"%Y-%m-%d\")    #partition\r\n",
        "\r\n",
        "dataverse_customer_table_df.write.format(\"csv\").option(\"header\",True) .mode(\"overwrite\").save(f\"abfss://{bronze_container_name}@{storage_account_name}.dfs.core.windows.net/{dataverse_customer_table_name}/{partition_date}\")"
      ]
    }
  ]
}